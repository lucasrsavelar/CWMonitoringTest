# Transaction Anomaly Monitor

Anomaly detection system for financial transactions, composed of a FastAPI backend, an ensemble machine learning model and a web dashboard.

---

## Requirements

Programming language: Python 3.14. A virtual environment is recommended to keep dependencies isolated. The Anaconda distribution is suggested both as an environment manager and as a Python installation. To create an environment using Anaconda, open the Anaconda Prompt and run:

```bash
conda create --name <env_name> python=3.14
```

A Python-driven IDE or an IDE with Python extensions support is also recommended. This project was developed using the Antigravity IDE, which includes AI agent support (models used include Gemini 3 Flash and Claude Sonnet/Opus 4.6). The models were used as support tools for generating ideas, suggesting improvements and fixing bugs.

Dependencies: all required dependencies are listed in `requirements.txt`. To install them, run:

```bash
pip install -r requirements.txt
```

Alternatively, open `requirements.txt` and install each dependency manually using your package manager of choice (pip or conda).

Database: **PostgreSQL** running locally on port `5432`. pgAdmin 4 is the recommended GUI and was used during development.

---

## Quick Start

1. Set up a local PostgreSQL database on port `5432`. Create tables using `solvetheproblem.sql`. Import `transactions.csv` data into the `transactions` table.

2. Install dependencies:
```bash
pip install -r requirements.txt
```

3. Start the API:
```bash
uvicorn TransactionsController:app --reload
```

4. Open `Dashboard.html` in a browser.

## 1. Database

### Connection

The connection is managed by the `DatabaseConnection` class (`DatabaseConnection.py`). Default connection string:

```
postgresql://postgres:postgres@localhost:5432/cloudwalk
```

To use a different connection string, pass it via the constructor:

```python
dbc = DatabaseConnection("postgresql://<user>:<password>@<host>:<port>/<dbname>")
```

### Table `transactions`

Data from `transactions.csv` was imported into the `transactions` table (see `solvetheproblem.sql` for the full schema). Each row represents **one status for a specific timestamp**:

| Column           | Type        | Description                                              |
|------------------|-------------|----------------------------------------------------------|
| `transaction_id` | `integer`   | Primary key, generated by `transaction_id_seq`           |
| `date_hour`      | `timestamp` | Time window timestamp (e.g. `2025-07-12 13:45:00`)      |
| `status`         | `varchar`   | Transaction status: `approved`, `denied`, `failed`, `refunded`, `reversed`, `backend_reversed` |
| `amount`         | `integer`   | Number of transactions with this status at this timestamp |

> A single `date_hour` has 6 rows, one per status.

### Available methods — `transactions`

#### `getTransactionsByMinute(start_date?, end_date?)`
Aggregates transactions by `date_hour`, returning a DataFrame with one column per status and the total number of transactions in each timestamp. Optional date filters in `YYYY-MM-DD HH:MM:SS` format.

```sql
SELECT
    date_hour,
    SUM(CASE WHEN status = 'approved' THEN amount ELSE 0 END) AS approved,
    SUM(CASE WHEN status = 'denied' THEN amount ELSE 0 END) AS denied,
    SUM(CASE WHEN status = 'failed' THEN amount ELSE 0 END) AS failed,
    SUM(CASE WHEN status = 'refunded' THEN amount ELSE 0 END) AS refunded,
    SUM(CASE WHEN status = 'reversed' THEN amount ELSE 0 END) AS reversed,
    SUM(CASE WHEN status = 'backend_reversed' THEN amount ELSE 0 END) AS backend_reversed,
    SUM(amount) AS total_transactions
FROM transactions
WHERE date_hour >= '2025-07-12 13:45:00' AND date_hour <= '2025-07-14 13:45:00' -- Optional
GROUP BY date_hour
ORDER BY date_hour;
```

#### `getAllTransactions(start_date?, end_date?)`
Returns all raw rows from the table, with optional date filters.

```sql
SELECT *
FROM transactions
WHERE date_hour >= '2025-07-12 13:45:00' AND date_hour <= '2025-07-14 13:45:00' -- Optional
ORDER BY date_hour;
```

#### `getMaxValueByStatus()`
Returns the historical peak `amount` for each non-approved status. Used as thresholds for the rule-based detection layer.

```sql
SELECT
    status,
    MAX(amount) AS max_amount
FROM transactions
WHERE status <> 'approved'
GROUP BY status;
```

#### `getMaxRateByStatus()`
Returns the highest observed rate (status / total) across all timestamps for each risk status. Also used for rate-based rules.

```sql
WITH aggregated AS (
    SELECT
        date_hour,
        SUM(CASE WHEN status = 'denied' THEN amount ELSE 0 END) AS denied,
        SUM(CASE WHEN status = 'failed' THEN amount ELSE 0 END) AS failed,
        SUM(CASE WHEN status = 'refunded' THEN amount ELSE 0 END) AS refunded,
        SUM(CASE WHEN status = 'reversed' THEN amount ELSE 0 END) AS reversed,
        SUM(CASE WHEN status = 'backend_reversed' THEN amount ELSE 0 END) AS backend_reversed,
        SUM(amount) AS total
    FROM transactions
    GROUP BY date_hour
)

SELECT
    MAX(denied::float / NULLIF(total, 0)) AS denied_rate,
    MAX(failed::float / NULLIF(total, 0)) AS failed_rate,
    MAX(refunded::float / NULLIF(total, 0)) AS refunded_rate,
    MAX(reversed::float / NULLIF(total, 0)) AS reversed_rate,
    MAX(backend_reversed::float / NULLIF(total, 0)) AS backend_reversed_rate
FROM aggregated;
```

#### `insertTransactions(date_hour, amounts)`
Inserts records into the transactions table. Receives a timestamp and a `{status: amount}` dictionary.

```sql
INSERT INTO transactions (date_hour, status, amount)
VALUES ('2025-07-15 13:45:00', 'approved', 117),
       ('2025-07-15 13:45:00', 'denied', 3),
       ('2025-07-15 13:45:00', 'failed', 0),
       ('2025-07-15 13:45:00', 'reversed', 1),
       ('2025-07-15 13:45:00', 'backend_reversed', 0),
       ('2025-07-15 13:45:00', 'refunded', 1);
```

Usage example:

```python
dbc.insertTransactions("2025-07-15 13:45:00", {
    "approved": 117,
    "denied": 3,
    "failed": 0,
    "reversed": 1,
    "backend_reversed": 0,
    "refunded": 1,
})
```

---

### Table `anomalies`

Persistently stores all detected anomalies:

| Column            | Type        | Description                                              |
|-------------------|-------------|----------------------------------------------------------|
| `anomaly_id`      | `integer`   | Primary key, generated by `anomaly_id_seq`               |
| `date_hour`       | `timestamp` | Timestamp of the anomalous transaction                   |
| `main_feature`    | `varchar`   | Primary risk feature identified                          |
| `anomaly_message` | `text`      | Detailed description of the metrics that triggered       |
| `ensemble_score`  | `numeric`   | ML ensemble score (`NULL` for rule-based detections)     |

Storing anomalies in the database provides a persistent history and makes the data easy to query for graphs, dashboards and reporting.

### Available methods — `anomalies`

#### `getAnomalies()`
Returns all records from the `anomalies` table ordered by `date_hour DESC`.

```sql
SELECT *
FROM anomalies
ORDER BY date_hour DESC
```

#### `insertAnomaly(date_hour, anomaly_data)`
Inserts an anomaly record. The `anomaly_data` dictionary must contain:
```python
{
    "main_feature":    "backend_reversed",
    "anomaly_message": "backend_reversed has a value of 30.0...",
    "ensemble_score":  0.9341  # or None for rule-based detections
}
```

```sql
INSERT INTO anomalies (date_hour, main_feature, anomaly_message, ensemble_score)
VALUES ('2025-07-15 13:45:00', 'backend_reversed', 'backend_reversed has a value of 30.0...', 0.9341);
```

---

## 2. Anomaly Detection Model

Implemented in `AnomalyDetectionModel.py`. Uses a set of pre-defined rules plus an **ensemble of three unsupervised models** from PyOD:

| Model   | Weight | Algorithm                          |
|---------|--------|------------------------------------|
| IForest | 0.4    | Isolation Forest                   |
| COPOD   | 0.3    | Copula-Based Outlier Detection     |
| ECOD    | 0.3    | Empirical Cumulative Distribution  |

The hybrid approach combines the advantages of rule-based and score-based detection. Rules quickly flag extreme and sudden changes, while ML models can detect subtler shifts that still warrant attention.

### Rule-based detection

Before passing data to the ML model, the system applies a **deterministic rule layer**: it compares each transaction's metrics against the **historical maximum** for each risk metric, loaded via `getMaxValueByStatus()` and `getMaxRateByStatus()` at startup (`start()`).

Metrics monitored by the rules (`ALL_TRESHOLDS`):

| Metric                  | Type           |
|-------------------------|----------------|
| `denied`                | absolute value |
| `failed`                | absolute value |
| `refunded`              | absolute value |
| `reversed`              | absolute value |
| `backend_reversed`      | absolute value |
| `denied_rate`           | relative rate  |
| `failed_rate`           | relative rate  |
| `refunded_rate`         | relative rate  |
| `reversed_rate`         | relative rate  |
| `backend_reversed_rate` | relative rate  |

If any metric exceeds its historical maximum, a rule-based anomaly is returned immediately (ML is skipped). These rules allow extreme data changes to be captured and notified quickly.

### ML — Chosen models

Each ML model, depending on its method and structure, is better suited to capture different types of anomalies: some detect global outliers better, others identify local deviations. Using only one model would restrict the system to that model's biases, increasing the chance of missing anomalies or generating false positives. The chosen mitigation strategy is a **model ensemble**: if an anomalous pattern goes undetected by one model, it is unlikely to pass all others simultaneously. In practice, this reduces both false positives (unnecessary alerts causing operational fatigue) and false negatives (real anomalies that go undetected).

Three models were chosen to balance detection quality with training and inference performance:

**Isolation Forest**
   - Detects anomalies by how easily a point can be isolated
   - Rare points are separated from the rest with few random cuts in a decision tree
   - Robust in high dimensionality and makes no distributional assumptions

**COPOD (Copula-Based Outlier Detection)**
   - Models the statistical dependency between features using copula functions, which account for feature correlation
   - Effective for detecting anomalies that only emerge from the combination of variables

**ECOD (Empirical Cumulative Distribution-Based Outlier Detection)**
   - Estimates the empirical distribution of each feature independently
   - Combines distribution tails to score anomalies based on the principle that they are outliers
   - Computationally efficient

All three models are recommended for outlier detection, which aligns well with this task. Each operates differently, combining distinct perspectives when flagging an anomaly.

Other models were considered but discarded:

**KNN (K-Nearest Neighbors)**
   - Classifies a point as anomalous when its average distance to its K nearest neighbors is high
   - Computationally inefficient and very sensitive to different scales and correlated features, which applies here

**HBOS (Histogram-Based Outlier Score)**
   - Builds a histogram per feature and scores anomalies based on how often a value falls in low-frequency bins
   - Assumes feature independence, redundant with ECOD in this context

### ML — Features used

For each time window, the model uses:

- Raw counts: `approved`, `denied`, `failed`, `refunded`, `reversed`, `backend_reversed`
- Rates relative to total: `approved_rate`, `denied_rate`, etc.
- Cyclical time components: `hour_sin`, `hour_cos`, `minute_sin`, `minute_cos`

Hour and minute are encoded as sine/cosine to improve model interpretation of time. For example, 23:00 is close to 00:00, but treating raw values would make models interpret 23 as far from 0. The transformation adds the cyclical notion of time.

### ML — Training and persistence

At startup (`model.start()`), the model checks whether a trained artefact exists in `models/`. If it does, it loads it; otherwise, it trains from all data in the database.

Retraining on every startup or API call is too expensive for this use case, so the model is trained once and reused. In production, periodic retraining with more, fresh data is recommended.

Persisted files:
```
models/
  iforest.pkl
  copod.pkl
  ecod.pkl
  scaler.pkl
  metadata.pkl   ← threshold, feature_names, score_ranges
```

Configurable parameters in `AnomalyDetectionModel.py`:

| Constant              | Default | Description                                        |
|-----------------------|---------|----------------------------------------------------|
| `CONTAMINATION`       | `0.02`  | Expected fraction of anomalies in training data    |
| `THRESHOLD_PERCENTILE`| `90`    | Ensemble score percentile used as the anomaly cut-off |

`CONTAMINATION` tells the models what proportion of training data is expected to be anomalous, affecting how each model calibrates its internal scores. Typical values range from 0.5–5%. 2% was chosen here to balance sensitivity: not so low that anomalies slip through, not so restrictive that normal data is over-flagged.

`THRESHOLD_PERCENTILE` means only the top 10% of scores are classified as anomalies, regardless of absolute score value. This approach is preferable to a fixed threshold because it adapts to the real score distribution. 90% was chosen to be slightly stricter than the more common 95%.

Both values should be revisited after accumulating real-world data and operational feedback. If the team reports many false positives, increasing the percentile to 95–97 reduces sensitivity. If real anomalies are being missed, reducing to 80–85 increases coverage.

### ML — Ensemble score

The final score is the weighted average of each model's normalized scores:

```
ensemble_score = 0.4 × iforest + 0.3 × copod + 0.3 × ecod
```

A transaction is classified as an anomaly if `ensemble_score >= threshold`.

A simple average (equal weights) would assume all models are equally reliable for the problem, which is not always true. The weighting system assigns distinct confidence to each model based on data characteristics.

IsolationForest received the highest weight (0.4) for two reasons:
   - It is more robust for heterogeneous features (transaction data mixes raw counts, rates, and time features)
   - It is less sensitive to outliers in training data than distribution-based models, which matters since historical data may contain unlabelled anomalies

COPOD and ECOD receive equal weights (0.3 each) because, despite different approaches, both operate in the statistical distribution space and tend to agree on clear cases. There is no explicit reason in this context to favour one over the other.

In production, ideal weights depend on real data. Empirical validation using metrics such as AUC-ROC or precision-recall is recommended once labels become available.

---

## 3. API

Start with:

```bash
uvicorn TransactionsController:app --reload
```

Available at `http://localhost:8000`.

### Endpoints

#### `POST /predict`

Analyses a transaction time window and returns whether it is anomalous.

**Request body:**
```json
{
  "timestamp": "2025-07-15 13:45:00",
  "approved": 117,
  "denied": 3,
  "failed": 0,
  "reversed": 0,
  "backend_reversed": 0,
  "refunded": 1
}
```

**Internal flow:**
1. Inserts the transaction into the database via `insertTransactions`
2. **Layer 1 — Rules:** compares each metric against the historical maximum
   - If any metric exceeds the limit → returns anomaly immediately, inserts into `anomalies`, sends Slack notification
3. **Layer 2 — ML model:** runs `model.predict()` with the ensemble
   - If `ensemble_score < threshold` → returns `is_anomaly: false`
   - Otherwise → `is_anomaly: true` and continues
4. Runs `model.explain()` to identify features with the highest z-score
5. Filters risk features (`ALERT_FEATURES`). If none trigger → `is_anomaly: false`
   - This filter prevents, for example, a high `approved` rate from being treated as an anomaly
6. Otherwise → returns details, inserts into `anomalies`, sends Slack notification

**Response (normal):**
```json
{
  "message": "No anomaly detected.",
  "is_anomaly": false,
  "body": null
}
```

**Response (anomaly):**
```json
{
  "message": "Anomaly detected.",
  "is_anomaly": true,
  "body": {
    "date_hour": "2025-07-15 13:45:00",
    "main_feature": "reversed",
    "details": "reversed has a z-score of 3.12. This value is higher than historical average.\n",
    "ensemble_score": 0.9341
  }
}
```

**Configurable thresholds in `TransactionsController.py`:**

| Constant                  | Default | Description                                                      |
|---------------------------|---------|------------------------------------------------------------------|
| `ANOMALY_ALERT_THRESHOLD` | `0`     | Minimum z-score for a risk feature to trigger an alert (ML only) |
| `ANOMALY_LOG_THRESHOLD`   | `1.5`   | Minimum z-score for a feature to appear in the anomaly log (ML only) |

These variables control when the model raises an alert (`ANOMALY_ALERT_THRESHOLD`) and when that anomaly is actually logged and users are notified (`ANOMALY_LOG_THRESHOLD`). Any feature with a z-score above 0 (i.e. above the mean) triggers a model alert, but not every feature with a positive z-score needs to be logged (a z-score of 0.5 is above average but rarely indicates a real problem). This control keeps the log clean and focused on features that actually drove the alert.

Anomalies typically have a z-score ≥ 2. To make the detection model slightly stricter, the minimum z-score required for a log entry was set to 1.5.

---

#### `GET /transactions`

Returns transactions aggregated by minute for the dashboard chart.

| Query param  | Format                | Required |
|--------------|-----------------------|----------|
| `start_date` | `YYYY-MM-DD HH:MM:SS` | No       |
| `end_date`   | `YYYY-MM-DD HH:MM:SS` | No       |

**Example:**
```
GET /transactions?start_date=2025-07-13 14:00:00&end_date=2025-07-13 15:00:00
```

---

#### `GET /anomalies`

Returns all anomalies persisted in the `anomalies` table, ordered from most recent to oldest.

```json
[
  {
    "date_hour": "2025-07-15 13:47:00",
    "main_feature": "backend_reversed",
    "anomaly_message": "backend_reversed has a value of 30.0. This value is higher than the maximum historical value for this metric.",
    "ensemble_score": null
  }
]
```

> `ensemble_score` is `null` for rule-based detections.

---

## 4. Notifications (Slack)

Implemented in `SlackNotifier.py`. Every detected anomaly (rule-based or ML-based) triggers a message in the configured Slack channel via Incoming Webhook.

The message includes timestamp, main feature, ensemble score, and details of the metrics that triggered the anomaly.

The webhook URL is configured via the `SLACK_WEBHOOK_URL` constant in `SlackNotifier.py`.

![Slack Anomaly Notification](slack_notification.png)

Slack was chosen for its widespread use in team communication and its straightforward Python integration. Depending on the organization's structure, alerts can be routed to other channels (email, Discord, Telegram or internal tools) by implementing a notifier class and adjusting the send method in `TransactionsController.py`.

---

## 5. Dashboard

Open `Dashboard.html` directly in a browser (no web server required).

Features:
- Transaction volume chart by minute (auto-refresh every 30s)
- Status and date range filters (`start_date` / `end_date`)
- Cards with totals per status
- Form to submit and analyse a transaction
- Clickable anomaly log with expandable details (data persisted in the database)

Using a plain HTML file in this context allows simple data observation without additional tooling, while still providing the desired features (real-time, filters, charts). In production, integration with dedicated observability tools offering greater operational support (e.g. Grafana + Prometheus) would be recommended.